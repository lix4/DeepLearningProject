{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf         \n",
    "from keras import backend as K  # needed for mixing TensorFlow and Keras commands \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1.0 \n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation,Flatten\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = './Trimmed%d/trim%d_resized.mp4'%(3,3)\n",
    "# capture = cv2.VideoCapture(path)\n",
    "# r, frame = capture.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv2.imshow('test',frame)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code above confirmed frames are real images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20520, 240, 240, 3)\n",
      "./Trimmed1/trim1_resized.mp4\n",
      "4187\n",
      "./Trimmed2/trim2_resized.mp4\n",
      "2267\n",
      "./Trimmed3/trim3_resized.mp4\n",
      "4570\n",
      "./Trimmed4/trim4_resized.mp4\n",
      "5036\n",
      "./Trimmed5/trim5_resized.mp4\n",
      "4460\n"
     ]
    }
   ],
   "source": [
    "total_data_length = 20520\n",
    "each_length = np.array([4187, 2267, 4570, 5036, 4460])\n",
    "frameWidth = 240\n",
    "frameHeight = 240\n",
    "# for k in range(5):\n",
    "#     video_index = k + 1\n",
    "#     path = './Trimmed%d/trim%d_resized.mp4'%(video_index,video_index)\n",
    "#     print(path)\n",
    "#     capture = cv2.VideoCapture(path)\n",
    "#     frameCount = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     frameWidth = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     frameHeight = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     total_frames += frameCount\n",
    "#     print(frameCount)\n",
    "#     print(frameHeight)\n",
    "#     print(frameWidth)\n",
    "    \n",
    "\n",
    "\n",
    "frames = np.empty((total_data_length, frameWidth, frameHeight, 3), np.dtype('uint8'))\n",
    "print(frames.shape)\n",
    "\n",
    "\n",
    "index = 0\n",
    "\n",
    "for k in range(5):\n",
    "    ret = True\n",
    "    video_index = k + 1\n",
    "    path = './Trimmed%d/trim%d_resized.mp4'%(video_index,video_index)\n",
    "    print(path)\n",
    "    capture = cv2.VideoCapture(path)\n",
    "    current_length = each_length[k]\n",
    "    print(current_length)\n",
    "    for j in range(current_length):\n",
    "        ret, frame = capture.read()\n",
    "        frames[index, :, :, :] = frame\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data1/E8D2.csv\n",
      "./Data1/E84F.csv\n",
      "./Data1/E91B.csv\n",
      "./Data1/E863.csv\n",
      "./Data1/E887.csv\n",
      "./Data1/E906.csv\n",
      "./Data1/E912.csv\n",
      "./Data2/E8D2.csv\n",
      "./Data2/E84F.csv\n",
      "./Data2/E91B.csv\n",
      "./Data2/E863.csv\n",
      "./Data2/E887.csv\n",
      "./Data2/E906.csv\n",
      "./Data2/E912.csv\n",
      "./Data3/E8D2.csv\n",
      "./Data3/E84F.csv\n",
      "./Data3/E91B.csv\n",
      "./Data3/E863.csv\n",
      "./Data3/E887.csv\n",
      "./Data3/E906.csv\n",
      "./Data3/E912.csv\n",
      "./Data4/E8D2.csv\n",
      "./Data4/E84F.csv\n",
      "./Data4/E91B.csv\n",
      "./Data4/E863.csv\n",
      "./Data4/E887.csv\n",
      "./Data4/E906.csv\n",
      "./Data4/E912.csv\n",
      "./Data5/E8D2.csv\n",
      "./Data5/E84F.csv\n",
      "./Data5/E91B.csv\n",
      "./Data5/E863.csv\n",
      "./Data5/E887.csv\n",
      "./Data5/E906.csv\n",
      "./Data5/E912.csv\n"
     ]
    }
   ],
   "source": [
    "name_string = ['E8D2', 'E84F', 'E91B', 'E863', 'E887', 'E906', 'E912']\n",
    "\n",
    "for a in range(5):\n",
    "    dir_index = a + 1\n",
    "    for b in range(7):\n",
    "        file_name = name_string[b]\n",
    "        path = './Data%d/%s.csv'%(dir_index, file_name)\n",
    "        print(path)\n",
    "        df = pd.read_csv(path, nrows=each_length[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(frames.shape)\n",
    "print(df[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Hyperparameters(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.depth1 = 0\n",
    "        self.depth2 = 0\n",
    "        self.filters = 0\n",
    "        self.nodes = 0\n",
    "        self.stopping = 0\n",
    "        self.dropout = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GenHyperparameters():\n",
    "    hp = Hyperparameters() \n",
    "#     hp.depth1 = np.random.choice([2, 3, 4, 5])\n",
    "#     hp.depth2 = np.random.choice([1, 2, 3])\n",
    "#     hp.filters = np.random.choice([16, 32, 64])\n",
    "#     hp.nodes = np.random.choice([16, 32, 64, 128])\n",
    "#     hp.stopping = np.random.choice([10, 15])\n",
    "#     hp.dropout = np.random.choice([0.1, 0.5])\n",
    "    hp.depth1 = np.random.choice([3])\n",
    "    hp.depth2 = np.random.choice([2])\n",
    "    hp.filters = np.random.choice([64])\n",
    "    hp.nodes = np.random.choice([128])\n",
    "    hp.stopping = np.random.choice([10])\n",
    "    hp.dropout = np.random.choice([0.1])\n",
    "    return hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BuildModel(hp):\n",
    "    \n",
    "    def BuildModule(model,depth=1,filters=16,input_flag=True):\n",
    "        # < code ommitted >\n",
    "        for j in np.arange(depth)+1:\n",
    "            if input_flag:\n",
    "                model.add(Conv2D(filters, 3, strides = 2, padding='same', input_shape=(240, 240, 3)))\n",
    "                input_flag = False\n",
    "            elif j == depth:\n",
    "                filters = filters * 2\n",
    "                model.add(Conv2D(filters, 3, strides = 4, padding='same'))\n",
    "            else:\n",
    "                model.add(Conv2D(filters, 3, strides = 2, padding='same'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation('relu'))\n",
    "        return (model,filters,input_flag)\n",
    "\n",
    "    filters = hp.filters\n",
    "    input_flag = True\n",
    "    model = Sequential()\n",
    "    for k in np.arange(hp.depth1) + 1:\n",
    "        (model,filters,input_flag) = BuildModule(model,depth=hp.depth2,\n",
    "                filters=filters,input_flag=input_flag)\n",
    "        print(filters)\n",
    "\n",
    "    # FC Module\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hp.nodes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(hp.dropout))\n",
    "    model.add(Dense(hp.nodes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(54))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N      = 1000\n",
    "EPOCHS = 10\n",
    "BATCH  = 1000\n",
    "TRIALS = 1 \n",
    "\n",
    "cols = ['depth1','depth2','filters','nodes','parameters','stopping','dropout','epochs',\n",
    "    'time (min)','train error','val error','test error'2]\n",
    "df = pd.DataFrame(np.zeros((TRIALS,len(cols))).fill(np.nan),columns=cols)\n",
    "for trail in range(TRIALS):\n",
    "    print('trial = %d/%d' % (trial+1,TRIALS),flush=True)\n",
    "    try:\n",
    "        model = BuildModel(hp)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "        time_start = time.time()\n",
    "        hist = model.fit(x_train[:N,:],y_train[:N,:],\n",
    "            batch_size=BATCH,\n",
    "              epochs=EPOCHS,\n",
    "                validation_split=0.2,\n",
    "                verbose=0,\n",
    "                callbacks=[EarlyStopping(patience=hp.stopping)])\n",
    "        time_stop = time.time()\n",
    "        time_elapsed = (time_stop - time_start)/60\n",
    "        train_err = 1 - hist.history['acc'][-1]\n",
    "        val_err = 1 - hist.history['val_acc'][-1]\n",
    "        test_acc = model.evaluate(x_test,y_test,batch_size=BATCH,verbose=0)\n",
    "        test_err = 1 - test_acc[1]\n",
    "        df.loc[trial,'parameters']  = model.count_params()\n",
    "        df.loc[trial,'epochs']      = hist.epoch[-1]\n",
    "        df.loc[trial,'time (min)']  = time_elapsed\n",
    "        df.loc[trial,'train error'] = train_err \n",
    "        df.loc[trial,'val error']   = val_err \n",
    "        df.loc[trial,'test error']  = test_err\n",
    "    except:\n",
    "        print('warning --> exception occured')\n",
    "        df = df.sort_values('val error')\n",
    "        print(df.head().round(2),flush=True)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
