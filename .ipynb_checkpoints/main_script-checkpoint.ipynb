{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K  # needed for mixing TensorFlow and Keras commands\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1.0\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import losses\n",
    "\n",
    "\n",
    "# ## The code above confirmed frames are real images\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "total_data_length = 20520\n",
    "each_length = np.array([4187, 2267, 4570, 5036, 4460])\n",
    "frameWidth = 240\n",
    "frameHeight = 240\n",
    "\n",
    "frames = np.empty((total_data_length, frameWidth,\n",
    "                   frameHeight, 3), np.dtype('uint8'))\n",
    "print(frames.shape)\n",
    "\n",
    "\n",
    "index = 0\n",
    "\n",
    "for k in range(5):\n",
    "    ret = True\n",
    "    video_index = k + 1\n",
    "    path = './Trimmed%d/trim%d_resized.mp4' % (video_index, video_index)\n",
    "    print(path)\n",
    "    capture = cv2.VideoCapture(path)\n",
    "    current_length = each_length[k]\n",
    "    print(current_length)\n",
    "    for j in range(current_length):\n",
    "        ret, frame = capture.read()\n",
    "        frames[index, :, :, :] = frame\n",
    "        index += 1\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "name_string = ['E8D2', 'E84F', 'E91B', 'E863', 'E887', 'E906', 'E912']\n",
    "\n",
    "for a in range(5):\n",
    "    dir_index = a + 1\n",
    "#     videoDF\n",
    "    for b in range(7):\n",
    "        file_name = name_string[b]\n",
    "        path = './Data%d/%s.csv' % (dir_index, file_name)\n",
    "        print(path)\n",
    "        df = pd.read_csv(path, nrows=each_length[a])\n",
    "#         print(type(df))\n",
    "        if(b == 0):\n",
    "            videoDF = df\n",
    "        else:\n",
    "            videoDF = pd.concat([videoDF, df], axis=1)\n",
    "#         print(videoDF.shape)\n",
    "\n",
    "    if(a == 0):\n",
    "        totalDF = videoDF\n",
    "    else:\n",
    "        totalDF = pd.concat([totalDF, videoDF], axis=0)\n",
    "    print(totalDF.shape)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# print(frames.shape)\n",
    "print(totalDF.keys())\n",
    "del totalDF['Time Stamp']\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "del totalDF['Time Stamp Unix']\n",
    "print(totalDF.keys())\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "data_output = totalDF.values\n",
    "data_output.shape\n",
    "all_output = np.delete(data_output, (0), axis=0)\n",
    "#20520, 42\n",
    "\n",
    "\n",
    "# 4460,42\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "data_input = frames\n",
    "data_input\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "current = np.delete(data_input, (0), axis=0)\n",
    "previous = np.delete(data_input, (20519), axis=0)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "all_frames = np.array([current, previous])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "all_frames = all_frames.swapaxes(0, 1)\n",
    "all_frames.shape\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# need to create xTrain, yTrain, xTest, yTest\n",
    "#x is input\n",
    "#y is output\n",
    "x_train = all_frames[0:15000]\n",
    "x_test = all_frames[15000:20520]\n",
    "y_train = all_output[0:15000]\n",
    "y_test = all_output[15000:20520]\n",
    "# print(data_input.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "# ## Here is the end of data processing.\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class Hyperparameters(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.depth1 = 0\n",
    "        self.depth2 = 0\n",
    "        self.filters = 0\n",
    "        self.nodes = 0\n",
    "        self.stopping = 0\n",
    "        self.dropout = 0\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def GenHyperparameters():\n",
    "    hp = Hyperparameters()\n",
    "#     hp.depth1 = np.random.choice([2, 3, 4, 5])\n",
    "#     hp.depth2 = np.random.choice([1, 2, 3])\n",
    "#     hp.filters = np.random.choice([16, 32, 64])\n",
    "#     hp.nodes = np.random.choice([16, 32, 64, 128])\n",
    "#     hp.stopping = np.random.choice([10, 15])\n",
    "#     hp.dropout = np.random.choice([0.1, 0.5])\n",
    "    hp.depth1 = np.random.choice([3])\n",
    "    hp.depth2 = np.random.choice([2])\n",
    "    hp.filters = np.random.choice([64])\n",
    "    hp.nodes = np.random.choice([128])\n",
    "    hp.stopping = np.random.choice([10])\n",
    "    hp.dropout = np.random.choice([0.1])\n",
    "    return hp\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def BuildModel(hp):\n",
    "\n",
    "    def BuildModule(model, depth=1, filters=16, input_flag=True):\n",
    "        # < code ommitted >\n",
    "        for j in np.arange(depth) + 1:\n",
    "            if input_flag:\n",
    "                model.add(Conv3D(filters, 3, strides=2,\n",
    "                                 padding='same', input_shape=(2, 240, 240, 3)))\n",
    "                input_flag = False\n",
    "            elif j == depth:\n",
    "                filters = filters * 2\n",
    "                model.add(Conv3D(filters, 3, strides=4, padding='same'))\n",
    "            else:\n",
    "                model.add(Conv3D(filters, 3, strides=2, padding='same'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation('relu'))\n",
    "        return (model, filters, input_flag)\n",
    "\n",
    "    filters = hp.filters\n",
    "    input_flag = True\n",
    "    model = Sequential()\n",
    "    for k in np.arange(hp.depth1) + 1:\n",
    "        (model, filters, input_flag) = BuildModule(model, depth=hp.depth2,\n",
    "                                                   filters=filters, input_flag=input_flag)\n",
    "        print(filters)\n",
    "\n",
    "    # FC Module\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hp.nodes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(hp.dropout))\n",
    "    model.add(Dense(hp.nodes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(42))\n",
    "    return model\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "N = 20519  # need to adjust this to fit data\n",
    "EPOCHS = 10\n",
    "BATCH = 100\n",
    "TRIALS = 1  # need to increase trials eventually\n",
    "\n",
    "cols = ['depth1', 'depth2', 'filters', 'nodes', 'parameters', 'stopping', 'dropout', 'epochs',\n",
    "        'time (min)', 'train error', 'val error', 'test error']\n",
    "df = pd.DataFrame(np.zeros((TRIALS, len(cols))).fill(np.nan), columns=cols)\n",
    "for trial in range(TRIALS):\n",
    "    print('trial = %d/%d' % (trial + 1, TRIALS), flush=True)\n",
    "    hp = GenHyperparameters()\n",
    "#     try:\n",
    "    model = BuildModel(hp)\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='Adam', metrics=['accuracy'])\n",
    "    time_start = time.time()\n",
    "    hist = model.fit(x_train[:N, :], y_train[:N, :],\n",
    "                     batch_size=BATCH,\n",
    "                     epochs=EPOCHS,\n",
    "                     validation_split=0.2,\n",
    "                     verbose=0,\n",
    "                     callbacks=[EarlyStopping(patience=hp.stopping)])\n",
    "    time_stop = time.time()\n",
    "    time_elapsed = (time_stop - time_start) / 60\n",
    "    print(\"keys\")\n",
    "    print(hist.history.keys())\n",
    "    train_err = hist.history['loss'][-1]\n",
    "    val_err = hist.history['val_loss'][-1]\n",
    "    test_mse = model.evaluate(x_test, y_test, batch_size=BATCH, verbose=0)[0]\n",
    "    df.loc[trial, 'parameters'] = model.count_params()\n",
    "    df.loc[trial, 'epochs'] = hist.epoch[-1]\n",
    "    df.loc[trial, 'time (min)'] = time_elapsed\n",
    "    df.loc[trial, 'train error'] = train_err\n",
    "    df.loc[trial, 'val error'] = val_err\n",
    "    df.loc[trial, 'test error'] = test_mse\n",
    "    print('train_err', train_err)\n",
    "    print('val_err', val_err)\n",
    "    print('test_err', test_mse)\n",
    "#     except:\n",
    "    # print('warning --> exception occured')\n",
    "    # df = df.sort_values('val error')\n",
    "    # print(df.head().round(2),flush=True)\n",
    "    # print()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
